import streamlit as st
import json
import os
import datetime
import uuid
from openai import OpenAI

# ì˜¬ë°”ë¥¸ ë°©ë²•ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])
except Exception as e:
    st.error(f"OpenAI API í‚¤ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤: {e}")
    st.warning("Streamlit secrets.toml íŒŒì¼ì— OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    # ì˜ˆì‹œ ì„¤ì • ë°©ë²• ë³´ì—¬ì£¼ê¸°
    st.code("""
    # .streamlit/secrets.toml
    [openai]
    api_key = "your-api-key-here"
    """)
    # ëŒ€ì²´ í´ë¼ì´ì–¸íŠ¸ - ì‹¤ì œë¡œëŠ” ì‘ë™í•˜ì§€ ì•Šì§€ë§Œ ì˜¤ë¥˜ ë°©ì§€ìš©
    client = None

# ì˜¤ë¦¬ë³„ ì±„íŒ… ìƒí™© ì •ë³´
chat_info = {
    "ğŸ§  íŒ©í­ì˜¤ë¦¬": {
        "situation": "íŒ€ ì£¼ê°„ íšŒì˜ ì‹œê°„. ë¦¬ë”ëŠ” ì§€ë‚œì£¼ ê³¼ì—… ê²°ê³¼ë¥¼ ì ê²€í•˜ë©° ê°„ë‹¨í•œ í”¼ë“œë°±ì„ ì£¼ë ¤ í•œë‹¤. íŒ”ì§±ì„ ë‚€ íŒ©í­ì˜¤ë¦¬ëŠ” ê°€ë³ê²Œ ë„ë•ì´ì§€ë§Œ í‘œì •ì€ êµ³ì–´ ìˆê³ , ë¦¬ë”ë¥¼ ë˜‘ë°”ë¡œ ë³´ì§€ ì•ŠëŠ”ë‹¤. ë¦¬ë”ê°€ \"Cë‹˜, ì§€ë‚œì£¼ì— ì§„í–‰í•œ ë³´ê³ ì„œ ì´ˆì•ˆ ë´¤ì–´ìš”. ì´ë²ˆ ì£¼ ì•ˆì— ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì œì¶œí•´ì¤„ ìˆ˜ ìˆê² ì–´ìš”?\"ë¼ê³  ë§í•˜ì, íŒ©í­ì˜¤ë¦¬ëŠ” ë‹¨í˜¸í•˜ê²Œ ë˜ë¬»ëŠ”ë‹¤. \"ìˆ˜ì • ë°©í–¥ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ê·¸ëƒ¥ ë‹¤ì‹œ í•˜ë¼ëŠ” ê±´ ë¹„íš¨ìœ¨ì ì¼ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\""
    },
    "ğŸ’– í† ë‹¥ì˜¤ë¦¬": {
        "situation": "íŒ€ ì£¼ê°„ íšŒì˜ê°€ í•œì°½ì¸ ê°€ìš´ë°, ë¦¬ë”ëŠ” ì§€ë‚œì£¼ ê³¼ì—… ê²°ê³¼ë¥¼ ì ê²€í•˜ë©° í”¼ë“œë°±ì„ ì „í•˜ë ¤ í•œë‹¤. í† ë‹¥ì˜¤ë¦¬ëŠ” íŒ”ì§±ì„ ë¼ê³  ê°€ë³ê²Œ ë„ë•ì´ì§€ë§Œ, í‘œì •ì€ êµ³ì–´ ìˆê³  ë¦¬ë”ë¥¼ ë˜‘ë°”ë¡œ ë°”ë¼ë³´ì§€ ì•ŠëŠ”ë‹¤. ë¦¬ë”ê°€ \"Cë‹˜, ì§€ë‚œì£¼ì— ì§„í–‰í•œ ë³´ê³ ì„œ ì´ˆì•ˆ ë´¤ì–´ìš”. ì´ë²ˆ ì£¼ ì•ˆì— ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì œì¶œí•´ì¤„ ìˆ˜ ìˆê² ì–´ìš”?\"ë¼ê³  ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ê±´ë„¤ì, í† ë‹¥ì˜¤ë¦¬ëŠ” ì‚´ì§ ì›€ì¸ ëŸ¬ë“  ë“¯í•œ í‘œì •ìœ¼ë¡œ ë¬»ëŠ”ë‹¤. \"í˜¹ì‹œ... ìˆ˜ì •í•  ë•Œ ì œê°€ ì£¼ì˜í•´ì•¼ í•  ë¶€ë¶„ì´ ìˆì„ê¹Œìš”...? ì˜í•˜ê³  ì‹¶ì–´ì„œìš”.\""
    },
    "ğŸ›¡ï¸ ë„¤ë„¤ì˜¤ë¦¬": {
        "situation": "ì£¼ê°„ íšŒì˜ ì¤‘, ë¦¬ë”ëŠ” ì§€ë‚œì£¼ì— ì§„í–‰í•œ ê³¼ì—… ê²°ê³¼ë¥¼ ì ê²€í•˜ë©° ì§§ì€ í”¼ë“œë°±ì„ ì£¼ë ¤ í•œë‹¤. ë„¤ë„¤ì˜¤ë¦¬ëŠ” íŒ”ì§±ì„ ë¼ê³  ê°€ë³ê²Œ ë„ë•ì´ë‚˜, êµ³ì€ í‘œì •ìœ¼ë¡œ ë¦¬ë”ë¥¼ í”¼í•´ ì‹œì„ ì„ ëŒë¦°ë‹¤. ë¦¬ë”ê°€ \"Cë‹˜, ì§€ë‚œì£¼ì— ì§„í–‰í•œ ë³´ê³ ì„œ ì´ˆì•ˆ ë´¤ì–´ìš”. ì´ë²ˆ ì£¼ ì•ˆì— ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì œì¶œí•´ì¤„ ìˆ˜ ìˆê² ì–´ìš”?\"ë¼ê³  ë§í•˜ì, ë„¤ë„¤ì˜¤ë¦¬ëŠ” ì›€ì°”í•˜ë©° ëŒ€ë‹µí•œë‹¤. \"ì•„... ë„¤... ë°”ë¡œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤... í˜¹ì‹œ... ë§ì´ ë¶€ì¡±í–ˆë‚˜ìš”...?\""
    },
    "ğŸ¨ ë‚´ë§˜ì˜¤ë¦¬": {
        "situation": "íŒ€ ì£¼ê°„ íšŒì˜ ìë¦¬ì—ì„œ, ë¦¬ë”ëŠ” ì§€ë‚œì£¼ ê³¼ì—… ê²°ê³¼ë¥¼ ì ê²€í•˜ë©° í”¼ë“œë°±ì„ ì£¼ê³ ì í•œë‹¤. ë‚´ë§˜ì˜¤ë¦¬ëŠ” íŒ”ì§±ì„ ë¼ê³  ê°€ë³ê²Œ ë„ë•ì´ì§€ë§Œ, í‘œì •ì€ ë‹¤ì†Œ ë¬´ì‹¬í•˜ê³  ë¦¬ë”ë¥¼ ì§ì ‘ ë°”ë¼ë³´ì§€ ì•ŠëŠ”ë‹¤. ë¦¬ë”ê°€ \"Cë‹˜, ì§€ë‚œì£¼ì— ì§„í–‰í•œ ë³´ê³ ì„œ ì´ˆì•ˆ ë´¤ì–´ìš”. ì´ë²ˆ ì£¼ ì•ˆì— ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì œì¶œí•´ì¤„ ìˆ˜ ìˆê² ì–´ìš”?\"ë¼ê³  ìš”ì²­í•˜ì, ë‚´ë§˜ì˜¤ë¦¬ëŠ” ë°ì€ í†¤ìœ¼ë¡œ ì´ë ‡ê²Œ ë‹µí•œë‹¤. \"ìˆ˜ì •í•  ë•Œ ìƒˆë¡œìš´ í¬ë§·ì„ ì¢€ ì œì•ˆí•´ë´ë„ ë ê¹Œìš”? ê·¸ëƒ¥ í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ë‚˜ì„ ê²ƒ ê°™ì•„ì„œìš”ã…ã…\""
    },
    "ğŸ› ï¸ ì‹¤ì†ì˜¤ë¦¬": {
        "situation": "ì£¼ê°„ íšŒì˜ê°€ ì§„í–‰ ì¤‘ì´ë‹¤. ë¦¬ë”ëŠ” ì§€ë‚œì£¼ì— ìˆ˜í–‰ëœ ê³¼ì—… ê²°ê³¼ë¥¼ ì ê²€í•˜ê³  ìˆìœ¼ë©°, ì‹¤ì†ì˜¤ë¦¬ëŠ” íŒ”ì§±ì„ ë¼ê³  ê³ ê°œë¥¼ ë„ë•ì´ì§€ë§Œ í‘œì •ì€ ë”±ë”±í•˜ê³  ì‹œì„ ì„ í”¼í•˜ê³  ìˆë‹¤. ë¦¬ë”ê°€ \"Cë‹˜, ì§€ë‚œì£¼ì— ì§„í–‰í•œ ë³´ê³ ì„œ ì´ˆì•ˆ ë´¤ì–´ìš”. ì´ë²ˆ ì£¼ ì•ˆì— ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì œì¶œí•´ì¤„ ìˆ˜ ìˆê² ì–´ìš”?\"ë¼ê³  ìš”ì²­í•˜ì, ì‹¤ì†ì˜¤ë¦¬ëŠ” ì°¨ë¶„í•˜ê³  ê³„ì‚°ì ì¸ ì–´ì¡°ë¡œ ë˜ë¬»ëŠ”ë‹¤. \"ìˆ˜ì •í•œ ê²°ê³¼ê°€ ì´ë²ˆ í”„ë¡œì íŠ¸ KPIì— ë°˜ì˜ë˜ëŠ” ê±´ê°€ìš”? í™•ì¸í•˜ê³  ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\""
    }
}

# íˆìŠ¤í† ë¦¬ ì €ì¥ í´ë” ìƒì„±
HISTORY_FOLDER = "chat_history"
os.makedirs(HISTORY_FOLDER, exist_ok=True)

def get_gpt_response(messages, duck_id, duck_name):
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    # ì˜¤ë¦¬ í˜ë¥´ì†Œë‚˜ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system_prompts = {
        1: "ë‹¹ì‹ ì€ íŒ©í­ì˜¤ë¦¬ ì—­í• ì…ë‹ˆë‹¤. ê°ì • ì—†ì´ ë…¼ë¦¬ì™€ íš¨ìœ¨ì„±ë§Œ ìƒê°í•˜ë©°, ê²°ë¡ ë¶€í„° ë°”ë¡œ ë§í•˜ê³  ë¶ˆí•„ìš”í•œ ë§ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ëŒ€í™”ëŠ” ì‹¤ìš©ì„±ê³¼ íš¨ìœ¨ì„±ì´ ì¤‘ì‹¬ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
        2: "ë‹¹ì‹ ì€ í† ë‹¥ì˜¤ë¦¬ ì—­í• ì…ë‹ˆë‹¤. ìƒëŒ€ë°©ì˜ ê°ì •ì„ ë§¤ìš° ì¤‘ìš”ì‹œí•˜ê³ , ì¹­ì°¬ê³¼ ê³µê°ì„ ìì£¼ í‘œí˜„í•©ë‹ˆë‹¤. ë‹¤ì†Œ ì†Œì‹¬í•˜ê³  ëˆˆì¹˜ë¥¼ ë§ì´ ë³´ëŠ” ì„±ê²©ì…ë‹ˆë‹¤.",
        3: "ë‹¹ì‹ ì€ ë„¤ë„¤ì˜¤ë¦¬ ì—­í• ì…ë‹ˆë‹¤. ë§¤ìš° ì†Œê·¹ì ì´ê³  ë°©ì–´ì ì¸ ì„±ê²©ìœ¼ë¡œ, ì§€ì ì„ ë°›ìœ¼ë©´ ì›€ì¸ ëŸ¬ë“¤ê³  ìì‹ ê°ì´ ì—†ìŠµë‹ˆë‹¤. ë§ëì„ íë¦¬ê±°ë‚˜ 'ë„¤...'ë¼ê³  ì‘ë‹µí•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.",
        4: "ë‹¹ì‹ ì€ ë‚´ë§˜ì˜¤ë¦¬ ì—­í• ì…ë‹ˆë‹¤. ììœ ë¡­ê³  ì°½ì˜ì ì¸ ì‚¬ê³ ë¥¼ ê°€ì¡Œìœ¼ë©°, ê·œì¹™ì— ì–½ë§¤ì´ëŠ” ê²ƒì„ ì‹«ì–´í•©ë‹ˆë‹¤. í•­ìƒ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ê³  ìì‹ ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ì¼í•˜ë ¤ê³  í•©ë‹ˆë‹¤.",
        5: "ë‹¹ì‹ ì€ ì‹¤ì†ì˜¤ë¦¬ ì—­í• ì…ë‹ˆë‹¤. ëª¨ë“  ì¼ì˜ ì‹¤ì§ˆì  ì´ë“ê³¼ ì„±ê³¼ë¥¼ ì¤‘ì‹œí•˜ë©°, KPIë‚˜ ëª©í‘œ ë‹¬ì„±ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤. ê°ì •ì  ì„¤ë“ë³´ë‹¤ëŠ” ë°ì´í„°ì™€ ê²°ê³¼ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤."
    }

    # API ìš”ì²­ì„ ìœ„í•œ ë©”ì‹œì§€ ì¤€ë¹„
    formatted_messages = [
        {"role": "system", "content": system_prompts[duck_id]}
    ]

    # ëŒ€í™” ë‚´ìš© ì¶”ê°€
    for message in messages:
        formatted_messages.append({
            "role": message["role"],
            "content": message["content"]
        })

    try:
        if client is None:
            raise Exception("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # OpenAI API í˜¸ì¶œ (ìµœì‹  API)
        response = client.chat.completions.create(
            model="gpt-4",  # ë˜ëŠ” gpt-3.5-turbo
            messages=formatted_messages
        )
        return response.choices[0].message.content
    except Exception as e:
        # API ì˜¤ë¥˜ ì‹œ ë°±ì—… ì‘ë‹µ
        print(f"GPT API ì˜¤ë¥˜: {e}")
        backup_responses = {
            1: f"ê²°ë¡ ë¶€í„° ë§í•˜ìë©´, ë” íš¨ìœ¨ì ì¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            2: f"ì •ë§ ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! í•¨ê»˜ ìƒê°í•´ë³¼ê¹Œìš”?",
            3: f"ë„¤... ê·¸ë ‡ê²Œ í•  ìˆ˜ë„ ìˆê² ë„¤ìš”... í˜¹ì‹œ ë‹¤ë¥¸ ë°©ë²•ë„ ìˆì„ê¹Œìš”...?",
            4: f"ì œê°€ ììœ ë¡­ê²Œ ìƒê°í•´ë´¤ì–´ìš”! ì´ë ‡ê²Œ í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?",
            5: f"ì‹¤ì§ˆì  ì´ë“ì„ ë¶„ì„í•´ë³´ë©´, KPI í–¥ìƒì„ ìœ„í•´ì„œëŠ”..."
        }
        return backup_responses[duck_id]

def generate_feedback(chat_history):
    """
    ëŒ€í™” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ íŒ€ì¥ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í”¼ë“œë°±ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    prompt = f"""
    ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ íŒ€ì¥ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:

    {chat_history}
    
    ì´ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
    1. íŒ€ì¥ì˜ ê¸ì •ì ì¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ íŠ¹ì§•
    2. íŒ€ì¥ì˜ ë¶€ì •ì ì¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ íŠ¹ì§•
    3. ê¸ì •ê³¼ ë¶€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¢…í•© í”¼ë“œë°±
    
    ë”°ëœ»í•˜ê³  ì›ƒê¸´ í†¤, ì´ëª¨ì§€ í¬í•¨í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    ì‘ë‹µ í¬ë§·:
    ---
    ### ê¸ì •ì ì¸ ë¶€ë¶„ :
    - ë‚´ìš©1
    - ë‚´ìš©2
    ### ë¶€ì •ì ì¸ ë¶€ë¶„ :
    - ë‚´ìš©1
    - ë‚´ìš©2
    ### ì¢…í•© í”¼ë“œë°± :
    (ì—¬ê¸°ì— ììœ ë¡­ê²Œ ì¢…í•© ì½”ë©˜íŠ¸ë¥¼  í‘œì‹œí•´ ì£¼ì„¸ìš”.)
    """

    try:
        if client is None:
            raise Exception("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ìµœì‹  OpenAI API ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4",  # ë˜ëŠ” gpt-3.5-turbo
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
        return """
        ---
        ### ê¸ì •ì ì¸ ë¶€ë¶„ :
        - ëŒ€í™”ì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì…¨ë„¤ìš”
        - ì§€ì‹œì‚¬í•­ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ë ¤ê³  ë…¸ë ¥í–ˆì–´ìš”
        
        ### ë¶€ì •ì ì¸ ë¶€ë¶„ :
        - ìƒëŒ€ë°©ì˜ ë°˜ì‘ì— ì¢€ ë” ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ë©´ ì¢‹ê² ì–´ìš”
        - í”¼ë“œë°±ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì œê³µí•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”
        
        ### ì¢…í•© í”¼ë“œë°± :
        ì „ë°˜ì ìœ¼ë¡œ ì˜ í•˜ê³  ê³„ì‹œì§€ë§Œ, ìƒëŒ€ë°©ì˜ ì„±í–¥ì— ë§ê²Œ ì†Œí†µ ë°©ì‹ì„ ì¡°ê¸ˆ ë” ì¡°ì ˆí•˜ë©´ 
        ë” íš¨ê³¼ì ì¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì´ ë  ê²ƒ ê°™ì•„ìš”! ğŸ˜Š í™”ì´íŒ…! ğŸš€
        """

def save_chat_history(duck_name, messages, feedback):
    """
    ëŒ€í™” ë‚´ìš©ê³¼ í”¼ë“œë°±ì„ ë¡œì»¬ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    now = datetime.datetime.now()
    chat_id = str(uuid.uuid4())[:8]  # ê³ ìœ  ID ìƒì„±
    filename = f"{HISTORY_FOLDER}/chat_{now.strftime('%Y%m%d_%H%M%S')}_{chat_id}.json"

    data = {
        "duck_name": duck_name,
        "timestamp": now.strftime("%Y-%m-%d %H:%M:%S"),
        "messages": messages,
        "feedback": feedback
    }

    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return filename

def load_chat_histories():
    """
    ì €ì¥ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
    """
    histories = []
    for filename in os.listdir(HISTORY_FOLDER):
        if filename.endswith(".json"):
            try:
                with open(os.path.join(HISTORY_FOLDER, filename), "r", encoding="utf-8") as f:
                    data = json.load(f)
                    data["filename"] = filename
                    histories.append(data)
            except Exception as e:
                print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {filename}, {e}")

    # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
    histories.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    return histories

def display_chatbot(duck_id, duck, back_to_selection):
    """
    ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜

    Args:
        duck_id: ì„ íƒëœ ì˜¤ë¦¬ì˜ ID
        duck: ì˜¤ë¦¬ ì •ë³´ê°€ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬
        back_to_selection: ì„ íƒ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ëŠ” í•¨ìˆ˜
    """
    # ê° ì˜¤ë¦¬ë§ˆë‹¤ ê³ ìœ í•œ ì„¸ì…˜ í‚¤ ìƒì„±
    duck_session_key = f"duck_{duck_id}"

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if f"conversation_step_{duck_session_key}" not in st.session_state:
        st.session_state[f"conversation_step_{duck_session_key}"] = 0

    if f"messages_{duck_session_key}" not in st.session_state:
        st.session_state[f"messages_{duck_session_key}"] = []

        # ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
        duck_key = duck['name']
        if duck_key in chat_info:
            welcome_msg = chat_info[duck_key]["situation"]
        else:
            welcome_msg = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {duck['name']}ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"

        st.session_state[f"messages_{duck_session_key}"].append({"role": "assistant", "content": welcome_msg})

    if f"feedback_{duck_session_key}" not in st.session_state:
        st.session_state[f"feedback_{duck_session_key}"] = None

    if f"show_feedback_{duck_session_key}" not in st.session_state:
        st.session_state[f"show_feedback_{duck_session_key}"] = False

    # í˜„ì¬ ëŒ€í™” ì„¸ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    conversation_step = st.session_state[f"conversation_step_{duck_session_key}"]
    messages = st.session_state[f"messages_{duck_session_key}"]
    feedback = st.session_state[f"feedback_{duck_session_key}"]
    show_feedback = st.session_state[f"show_feedback_{duck_session_key}"]

    # ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
    st.write("---")

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³´ê¸° ì„¹ì…˜
    with st.expander("ì´ì „ ëŒ€í™” ê¸°ë¡ ë³´ê¸°"):
        histories = load_chat_histories()
        if not histories:
            st.info("ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected_history = st.selectbox(
                "ëŒ€í™” ê¸°ë¡ ì„ íƒ",
                options=histories,
                format_func=lambda x: f"{x['duck_name']} - {x['timestamp']}",
                key=f"history_select_{duck_session_key}"
            )

            if selected_history:
                st.subheader("ëŒ€í™” ë‚´ìš©")
                for msg in selected_history["messages"]:
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

                st.subheader("í”¼ë“œë°±")
                st.markdown(selected_history["feedback"])

    # ì±„íŒ… ë‚´ì—­ í‘œì‹œ
    for message in messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # í”¼ë“œë°± ëª¨ë‹¬ í‘œì‹œ
    if show_feedback and feedback:
        modal_container = st.container(border=True)
        with modal_container:
            st.subheader("ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í”¼ë“œë°±")
            st.markdown(feedback)

            if st.button("í™•ì¸", key=f"close_feedback_{duck_session_key}"):
                # íˆìŠ¤í† ë¦¬ ì €ì¥
                save_chat_history(duck['name'], messages, feedback)

                # ì„¸ì…˜ ì´ˆê¸°í™” ë° ëŒì•„ê°€ê¸°
                st.session_state[f"show_feedback_{duck_session_key}"] = False
                st.session_state[f"conversation_step_{duck_session_key}"] = 0
                st.session_state[f"messages_{duck_session_key}"] = []
                st.session_state[f"feedback_{duck_session_key}"] = None
                back_to_selection()
                st.rerun()

    # ë‚¨ì€ ëŒ€í™” íšŸìˆ˜ í‘œì‹œ
    if conversation_step < 3:
        st.info(f"ë‚¨ì€ ëŒ€í™” íšŸìˆ˜: {3 - conversation_step}ë²ˆ")

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (ëŒ€í™” ë‹¨ê³„ê°€ 3ë²ˆ ë¯¸ë§Œì¼ ë•Œë§Œ)
    if conversation_step < 3:
        if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key=f"chat_input_{duck_session_key}"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state[f"messages_{duck_session_key}"].append({"role": "user", "content": prompt})

            # ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)

            # GPTë¥¼ í†µí•œ ì˜¤ë¦¬ ì‘ë‹µ ìƒì„±
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                response = get_gpt_response(messages, duck_id, duck['name'])

            # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
            st.session_state[f"messages_{duck_session_key}"].append({"role": "assistant", "content": response})

            # ì‘ë‹µ í‘œì‹œ
            with st.chat_message("assistant"):
                st.markdown(response)

            # ëŒ€í™” ë‹¨ê³„ ì¦ê°€
            st.session_state[f"conversation_step_{duck_session_key}"] += 1
            conversation_step += 1

            # 3ë²ˆì§¸ ëŒ€í™”ê°€ ì™„ë£Œë˜ë©´ í”¼ë“œë°± ìƒì„±
            if conversation_step >= 3:
                with st.spinner("í”¼ë“œë°± ìƒì„± ì¤‘..."):
                    chat_history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in messages])
                    generated_feedback = generate_feedback(chat_history_text)
                    st.session_state[f"feedback_{duck_session_key}"] = generated_feedback

                    # í”¼ë“œë°± ëª¨ë‹¬ í‘œì‹œ
                    st.session_state[f"show_feedback_{duck_session_key}"] = True
                    st.rerun()

    # ì´ì „ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼
    if st.button("ë‹¤ë¥¸ ì˜¤ë¦¬ ì„ íƒí•˜ê¸°", key=f"back_button_{duck_session_key}"):
        # ëŒ€í™”ê°€ ëë‚˜ì§€ ì•Šì•˜ì„ ë•Œ ê²½ê³  ë©”ì‹œì§€
        if conversation_step > 0 and conversation_step < 3:
            st.warning("ëŒ€í™”ê°€ ì•„ì§ ëë‚˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‚˜ê°€ì‹œë©´ ì§„í–‰ ì¤‘ì¸ ëŒ€í™”ê°€ ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            if st.button("ê·¸ë˜ë„ ë‚˜ê°€ê¸°", key=f"confirm_back_{duck_session_key}"):
                st.session_state[f"conversation_step_{duck_session_key}"] = 0
                st.session_state[f"messages_{duck_session_key}"] = []
                st.session_state[f"feedback_{duck_session_key}"] = None
                back_to_selection()
                st.rerun()
        else:
            st.session_state[f"conversation_step_{duck_session_key}"] = 0
            st.session_state[f"messages_{duck_session_key}"] = []
            st.session_state[f"feedback_{duck_session_key}"] = None
            back_to_selection()
            st.rerun()